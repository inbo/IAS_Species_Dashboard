---
title: "Data_Prep"
author: "Sander Devisscher"
date: "10-6-2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
```

```{r general}
spec_ind <- read_delim("https://raw.githubusercontent.com/inbo/IAS_Species_Dashboard/master/Data/Lists/nameserver_species_identifiers_for_t0.csv", 
                       ";", escape_double = FALSE, col_types = cols(t0_from = col_date(format = "%d/%m/%Y"), 
                                                                    t0_to = col_date(format = "%d/%m/%Y"), 
                                                                    t1_from = col_date(format = "%d/%m/%Y"), 
                                                                    t1_to = col_date(format = "%d/%m/%Y")), 
                       trim_ws = TRUE, locale = locale("en"))

species_choices <- spec_ind %>% 
  filter(!is.na(Batch)) %>% 
  mutate(Species = case_when(grepl("Salvinia", gbifapi_acceptedScientificName) ~ "Salvinia auriculata Aubl.",
                             TRUE ~ gbifapi_acceptedScientificName)) %>% 
  distinct(Species, gbifapi_acceptedKey) 
```

```{r TrIAS}
df_ts <- read_tsv(here("data",
                       "input",
                       "df_timeseries.tsv"),
                  locale = locale("en"))

df_ts_sub <- df_ts %>% 
  filter(taxonKey %in% species_choices$gbifapi_acceptedKey) %>%
  group_by(taxonKey, year, classKey) %>%
  summarise(
    obs = sum(obs),
    cobs = sum(cobs),
    ncells = sum(pa_cobs),
    c_ncells = sum(pa_cobs)
  ) %>%
  ungroup()

write_tsv(df_ts_sub, here("Data",
                          "Interim",
               "df_timeseries_redux.tsv"))
```

```{r utms & stats general}
bioregions <- c("Atlantic", "Continental")
ts <- c("t0", "t1")
batches <- c("Batch1", "Batch2", "Batch3")
```

```{r utm_polygons}
utm_merged <- data.frame()

source(here("R-scripts",
            "make_geojsons.R"))

for(t in ts){
  for(b in batches){
    fn <- paste0("https://github.com/inbo/IAS_Species_Dashboard/raw/3_version1.0/Data/Spatial/",t, "_manageability_utmpolygons_", b, ".geojson")
    fn2 <- paste0(t, "_manageability_utmpolygons_", b)
    #Determine if url loads correctly (ea status_code == 200)
    if(httr::status_code(httr::GET(fn)) == 200){
      temp_utm <- readOGR(fn, fn2, stringsAsFactors = FALSE)
      temp_utm$tx <- t
      if(class(utm_merged) == "SpatialPolygonsDataFrame"){
        utm_merged <- rbind.SpatialPolygonsDataFrame(utm_merged, temp_utm)
      }else{
        utm_merged <- temp_utm
      }
    }else{
      next()
    }
  }
}

writeOGR(utm_merged, here("Data", "Spatial", "utm_merged.geojson"), layer="utm_merged", driver="GeoJSON",overwrite_layer=T)
```

```{r stats}
stats_merged <- data.frame()

for(t in ts){
  for(b in batches){
    fn <- paste0("https://raw.githubusercontent.com/inbo/IAS_Species_Dashboard/3_version1.0/Data/Input/", t, "_manageability_GridStats_", b, ".csv")
    if(httr::status_code(httr::GET(fn)) == 200){
      temp_stats <- read_delim(fn, delim = ";", locale = locale("en"))
      temp_stats$tx <- t
      if(nrow(stats_merged) > 0){
        stats_merged <- rbind(stats_merged, temp_stats)
      }else{
        stats_merged <- temp_stats
      }
    }else{
      next()
    }
  }
}

write_delim(stats_merged, here("Data", "Interim", "stats_merged.csv"), ";")
```

